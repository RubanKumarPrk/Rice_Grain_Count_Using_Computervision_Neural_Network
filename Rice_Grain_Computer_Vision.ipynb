{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Creating a Training Data Set"
      ],
      "metadata": {
        "id": "Abyub-GNvunE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yVwFBUwAHTqv"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing black image as background to display the contour of each grain\n",
        "bg = cv2.imread(\"black.jpg\")\n",
        "bg = cv2.cvtColor(bg, cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "RIeH5Y0gHZez"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#address to the directories of broken rice grain training set and full rice grain training set\n",
        "DIR_broken = r'/content/broken'\n",
        "DIR_full = r'/content/full'"
      ],
      "metadata": {
        "id": "B6ZCWWilHZru"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing the shape of background image that is to be used to resize the training images to fit the background\n",
        "IMG_SIZE = (bg.shape[1], bg.shape[0])"
      ],
      "metadata": {
        "id": "O6fHSqxmHZ3G"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating lists to store the training images of respective classes\n",
        "broken_data = []\n",
        "full_data = []\n",
        "\n",
        "#importing all the images of broken grains, resizing them to the size of background image\n",
        "for img in os.listdir(DIR_broken):\n",
        "    img_path = os.path.join(DIR_broken, img)\n",
        "    img_arr = cv2.imread(img_path)\n",
        "    img_arr = cv2.resize(img_arr, IMG_SIZE)\n",
        "    broken_data.append(img_arr)\n",
        "\n",
        "#importing all the images of broken grains, resizing them to the size of background image\n",
        "for img in os.listdir(DIR_full):\n",
        "    img_path = os.path.join(DIR_full, img)\n",
        "    img_arr = cv2.imread(img_path)\n",
        "    img_arr = cv2.resize(img_arr, IMG_SIZE)\n",
        "    full_data.append(img_arr)"
      ],
      "metadata": {
        "id": "PQlRz1oMHaCX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#method to preprocess the images\n",
        "def img_preprocess(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #converting the image to grayscale\n",
        "    blur = cv2.GaussianBlur(gray, (11,11), 0) #blurring the image to avoid noise\n",
        "    canny = cv2.Canny(blur, 30, 150, 3) #getting the edges\n",
        "    dilate = cv2.dilate(canny, (1,1), iterations = 2) #sharpening the edges\n",
        "    return dilate\n",
        "\n",
        "#lists to append the processed images\n",
        "broken = []\n",
        "full = []\n",
        "\n",
        "for i in broken_data:\n",
        "    broken.append(img_preprocess(i))\n",
        "\n",
        "for i in full_data:\n",
        "    full.append(img_preprocess(i))\n",
        "    \n",
        "#finding the contours of the broken rice grains and storing them in a list\n",
        "broken_cnt = []\n",
        "for i in broken:\n",
        "    (cnt, h_broken) = cv2.findContours(i.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    broken_cnt.append(cnt)\n",
        "    \n",
        "#finding the contours of the full rice grains and storing them in a list\n",
        "full_cnt = []\n",
        "for i in full:\n",
        "    (cnt, f_broken) = cv2.findContours(i.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    full_cnt.append(cnt)\n",
        "    \n",
        "#method to increase the size of contours to print on the background image\n",
        "def scale_contour(contour, scale):\n",
        "    moments = cv2.moments(contour) #finding the moments of the contour\n",
        "    midX = 0\n",
        "    midY = 0\n",
        "    if (moments['m00']!=0):\n",
        "        midX = int(round(moments[\"m10\"] / moments[\"m00\"]))\n",
        "        midY = int(round(moments[\"m01\"] / moments[\"m00\"]))\n",
        "    mid = np.array([midX, midY])\n",
        "    contour = contour - mid\n",
        "    contour = (contour * scale).astype(np.int32) #scaling the contour coordinates to the desired size\n",
        "    contour = contour + mid\n",
        "    return contour\n",
        "\n",
        "epoch = 0\n",
        "#putting the contours of the broken rice grain filled in white on the black background and saving it in the given address\n",
        "for j in broken_cnt:\n",
        "    for i in range(0, len(j)):\n",
        "        bg_copy = bg.copy()\n",
        "        cnt_scaled = scale_contour(j[i], 10)\n",
        "        cv2.fillPoly(bg_copy, pts =[cnt_scaled], color=(255,255,255)) #filling in the contours with white\n",
        "        cv2.imwrite(r'/content/train/broken_train/broken_%04d.png'%(epoch+1), bg_copy)\n",
        "        epoch+=1\n",
        "\n",
        "#putting the contours of the full rice grain filled in white on the black background and saving it in the given address       \n",
        "epoch = 0\n",
        "for j in full_cnt:\n",
        "    for i in range(0, len(j)):\n",
        "        bg_copy = bg.copy()\n",
        "        cnt_scaled = scale_contour(j[i], 10)\n",
        "        cv2.fillPoly(bg_copy, pts =[cnt_scaled], color=(255,255,255))\n",
        "        cv2.imwrite(r'/content/train/full_train/full_%04d.png'%(epoch+1), bg_copy) #filling in the contours with white\n",
        "        epoch+=1"
      ],
      "metadata": {
        "id": "k4VFbeKuHokc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Model"
      ],
      "metadata": {
        "id": "kv9yjU-bPlY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing all the dependancies\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
        "\n",
        "IMG_SIZE = (224,224) #setting the image size for the neural network\n",
        "\n",
        "train = [] #list to store the training data\n",
        "\n",
        "DIR = r'/content/train' #address to the directory of training data\n",
        "category = ['broken_train', 'full_train'] #folder names for the respective classes\n",
        "\n",
        "#iterating through both the folders and adding the images to the training data list\n",
        "for c in category:\n",
        "    folder =  os.path.join(DIR, c)\n",
        "    label = category.index(c) #0 for broken, 1 for full\n",
        "    for img in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, img) \n",
        "        img_arr = cv2.imread(img_path) #reading the images\n",
        "        img_arr = cv2.resize(img_arr, IMG_SIZE) #resizing the images to the size described above for CNN\n",
        "        train.append([img_arr, label]) #returning the data along with labels\n",
        "        \n",
        "#shuffling the data so the model can learn better\n",
        "random.shuffle(train)\n",
        "\n",
        "#break the dataset and store the features in X_train and labels in y_train\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for features, labels in train:\n",
        "    X_train.append(features)\n",
        "    y_train.append(labels)\n",
        "    \n",
        "#converting the data into numpy array\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "#normalising the pixel values\n",
        "X_train = X_train/255\n",
        "\n",
        "\n",
        "#creating the CNN model for classiying\n",
        "model = Sequential()\n",
        "\n",
        "#first CNN layer with 32 layers and feature extractor of size 3x3\n",
        "model.add(Conv2D(32, (3, 3), input_shape = X_train.shape[1:]))\n",
        "model.add(Activation('relu')) #Rectified Linear Unit as Activation function\n",
        "model.add(MaxPooling2D(pool_size = (2, 2))) #max pooling layer of size 2x2\n",
        "\n",
        "#second CNN layer with 32 layers and feature extractor of size 3x3\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu')) #Rectified Linear Unit as Activation function\n",
        "model.add(MaxPooling2D(pool_size = (2, 2))) #max pooling layer of size 2x2\n",
        "\n",
        "#third CNN layer with 64 layers and feature extractor of size 3x3\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu')) #Rectified Linear Unit as Activation function\n",
        "model.add(MaxPooling2D(pool_size = (2, 2))) #max pooling layer of size 2x2\n",
        "\n",
        "model.add(Flatten()) #Flattening to get 1D array of features\n",
        "model.add(Dense(64)) #defining the hidden layer with 64 neurons\n",
        "model.add(Activation('relu')) #Rectified Linear Unit as Activation function\n",
        "model.add(Dropout(0.5)) \n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax')) #activation function that returns the probability of a data lying in either classes\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy']) #compiling the model with the given parameters\n",
        "\n",
        "model.fit(X_train, y_train, epochs = 10, validation_split = 0.1) #training the model over the training dataset\n",
        "\n",
        "model.save(\"grain_classifier.h5\") #saving the CNN classifier model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L6X1RCfNuJR",
        "outputId": "c24b8b71-2a7c-412c-83e1-9527a30f030c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "125/125 [==============================] - 270s 2s/step - loss: 0.6726 - accuracy: 0.6021 - val_loss: 0.6476 - val_accuracy: 0.6014\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 267s 2s/step - loss: 0.6409 - accuracy: 0.6316 - val_loss: 0.6485 - val_accuracy: 0.6036\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 268s 2s/step - loss: 0.6066 - accuracy: 0.6832 - val_loss: 0.6569 - val_accuracy: 0.5878\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 275s 2s/step - loss: 0.5545 - accuracy: 0.7383 - val_loss: 0.6979 - val_accuracy: 0.6014\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 272s 2s/step - loss: 0.4837 - accuracy: 0.7784 - val_loss: 0.7500 - val_accuracy: 0.6216\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 270s 2s/step - loss: 0.4188 - accuracy: 0.8149 - val_loss: 0.7366 - val_accuracy: 0.6014\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 270s 2s/step - loss: 0.3469 - accuracy: 0.8485 - val_loss: 0.8737 - val_accuracy: 0.6194\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 271s 2s/step - loss: 0.2817 - accuracy: 0.8833 - val_loss: 1.0035 - val_accuracy: 0.5946\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 277s 2s/step - loss: 0.2248 - accuracy: 0.9138 - val_loss: 1.1359 - val_accuracy: 0.5946\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 274s 2s/step - loss: 0.1842 - accuracy: 0.9314 - val_loss: 1.2277 - val_accuracy: 0.5878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing Model"
      ],
      "metadata": {
        "id": "mhHO1x5MPpMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing all the dependencies\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "#importing the output csv file, the background image, and the saved model\n",
        "op = pd.read_csv('submission.csv')\n",
        "bg = cv2.imread('black.jpg')\n",
        "model = load_model('grain_classifier.h5')\n",
        "\n",
        "DIR = r'/content/test' #the address to the tesing data\n",
        "img = cv2.imread(r'/content/test/image_4.jpg') #reading the test images one by one\n",
        "\n",
        "#converting the test image to grayscale\n",
        "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "blur = cv2.GaussianBlur(gray, (11,11), 0) #blurring the images to avoid noise\n",
        "canny = cv2.Canny(blur, 30, 150, 3) #reading the edges of the grains\n",
        "dilate = cv2.dilate(canny, (1,1), iterations = 2) #dilating the image to sharpen and thicken the edges\n",
        "\n",
        "#getting the contours and storring it in a list\n",
        "(cnt, heirarchy) = cv2.findContours(dilate.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "#method to scale the contour coordinates to the desired size\n",
        "def scale_contour(contour, scale):\n",
        "    moments = cv2.moments(contour) #finding the moments\n",
        "    midX = 0\n",
        "    midY = 0\n",
        "    if (moments['m00']!=0):\n",
        "        midX = int(round(moments[\"m10\"] / moments[\"m00\"]))\n",
        "        midY = int(round(moments[\"m01\"] / moments[\"m00\"]))\n",
        "    mid = np.array([midX, midY])\n",
        "    contour = contour - mid\n",
        "    contour = (contour * scale).astype(np.int32) #scaling the contours to a desired size\n",
        "    contour = contour + mid\n",
        "    return contour\n",
        "\n",
        "#painting the contours on to the black background and saving the images in the given directory's address\n",
        "epoch = 0\n",
        "for i in cnt:\n",
        "    bg_copy = cv2.imread('black.jpg') #reading the black image\n",
        "    cnt_scaled = scale_contour(i, 10) #resizing the contour\n",
        "    cv2.fillPoly(bg_copy, pts =[cnt_scaled], color=(255,255,255)) #painting the contours on to the black image\n",
        "    cv2.imwrite(r'/content/test/test_image5/image_%04d.jpg'%(epoch+1), bg_copy) #saving the image in the desired address\n",
        "    epoch+=1\n",
        "    \n",
        "op.iloc[4, 1] = int(len(cnt))#the number of contours is the number of grains\n",
        "\n",
        "folder = r'/content/test/test_image5' #folder for the contour images of the test dataset\n",
        "X_test = []\n",
        "for img in os.listdir(folder):\n",
        "    img = os.path.join(folder, img)\n",
        "    img_arr = cv2.imread(img) #reading the images\n",
        "    img_arr = cv2.resize(img_arr, (224, 224)) #resizing the images to the desired size for the network to read\n",
        "    X_test.append(img_arr) #Adding it to the list of test data\n",
        "    \n",
        "X_test = np.array(X_test) #converting the list to array as neural network expects numpy as the input array\n",
        "\n",
        "pred = model.predict(X_test) #predict the probablities of the contours to be of a roken rice grain or a full rice grain\n",
        "pred = pred.tolist() #converting the prediction array to list for our convinience\n",
        "\n",
        "count = 0\n",
        "for [broken, full] in pred:\n",
        "    if(broken>full):\n",
        "        count+=1 #counting the number of data that has probability of being broken grain greater than that of being a full grain\n",
        "        \n",
        "op.iloc[4,2] = count #the count is the number of broken grains in the image\n",
        "\n",
        "op.to_csv('final_submission4.csv') #adding the values to the op dataframe and saving it to the final csv file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shd0Su1yPWfZ",
        "outputId": "2de2558a-f36e-4795-ad50-7c8e98e3bbba"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 11s 521ms/step\n"
          ]
        }
      ]
    }
  ]
}